{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download all by 1 ZONE 1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import urllib.request \n",
    "\n",
    "ZONE1_path = r'./ZONE1/'\n",
    "ZONE2_path = r'./ZONE2/'\n",
    "ZONE3_path = r'./ZONE3/'\n",
    "if not os.path.exists(ZONE1_path):\n",
    "    os.mkdir(ZONE1_path)\n",
    "if not os.path.exists(ZONE2_path):\n",
    "    os.mkdir(ZONE2_path)\n",
    "if not os.path.exists(ZONE3_path):\n",
    "    os.mkdir(ZONE3_path)\n",
    "    \n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'} \n",
    "\n",
    "url_start = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp?tid=5f1da434-ad44-4955-97d3-1ac4433603f1(203.204.81.115)'\n",
    "url_start = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp?tid=f61d5b9e-0eb7-4160-86c9-ab76e064cb8c(111.249.61.96)'\n",
    "url_each = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp'\n",
    "dkind = [\"OPP\",\"VAL\",\"REV\"] # \"REJ\" over 130K\n",
    "paths = [ZONE1_path,ZONE2_path,ZONE3_path]\n",
    "years = [102,103,104,105,106,107,108,109]\n",
    "ZONE1_targets_fore = [399,349,384,359,307,386,384,273]\n",
    "ZONE1_targets_back = [496,410,374,381,342,429,358,192]\n",
    "ZONE2_targets_fore = [134,101,95,96,77,88,101,78]\n",
    "ZONE2_targets_back = [174,156,139,97,101,125,79,53]\n",
    "ZONE3_targets_fore = [238,261,257,277,251,277,237.307]\n",
    "ZONE3_targets_back = [222,261,353,279,261,272,273,303]\n",
    "keys = [\"title\",\"kind\",\"markname\",\"url_images\",\"content\"]\n",
    "\n",
    "for num in range(2,3):\n",
    "#select type of judgement.\n",
    "    print(\"now is : kind\",dkind[num])\n",
    "\n",
    "    # year period select\n",
    "    for year in range(8):\n",
    "        try:\n",
    "            data_fore = {'state': 'queryResultJSONObject',\n",
    "            'searchConditions': '{\"datePubStart\":\"%s/01/01\",\"datePubEnd\":\"%s/06/31\",\"dptKind\":\"%s\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'%(years[year],years[year],dkind[num])\n",
    "                   }\n",
    "            data_back = {'state': 'queryResultJSONObject',\n",
    "            'searchConditions': '{\"datePubStart\":\"%s/07/01\",\"datePubEnd\":\"%s/12/31\",\"dptKind\":\"%s\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'%(years[year],years[year],dkind[num])\n",
    "                   }\n",
    "            res_fore = requests.post(url_start, headers=headers, data=data_fore)\n",
    "            res_back = requests.post(url_start, headers=headers, data=data_back)\n",
    "            \n",
    "            list_fore = json.loads(res_fore.text)\n",
    "            list_back = json.loads(res_back.text)\n",
    "            item_back = 0\n",
    "            item_fore = 0\n",
    "            \n",
    "            # crawler fore year data\n",
    "            for i in list_fore['receiveData']['resultArr']:\n",
    "                d1 = {}\n",
    "                try:\n",
    "                    kind_fore = i['DPT_KIND']\n",
    "                    mark_fore = i['MARK_NAME']\n",
    "                    no_fore = i['PUB_NO']\n",
    "                    title_fore = no_fore[-12:-1]\n",
    "#                     print(title_fore)\n",
    "                    file_fore = i['FILENAME']\n",
    "                    data_sfore = {'state': 'getContentByFileName',\n",
    "                                'filename': file_fore\n",
    "                                 }\n",
    "\n",
    "                    # crawler content\n",
    "                    res_sec_fore = requests.post(url_each, headers=headers, data=data_sfore)\n",
    "                    raw_content_fore = json.loads(res_sec_fore.text)\n",
    "                    content_fore = raw_content_fore['content']['content']\n",
    "\n",
    "                    #crawler image\n",
    "                    case_no = raw_content_fore['content']['main'][77:118]\n",
    "                    url_img = 'https://twtmsearch.tipo.gov.tw/SS0/SS0201_q.jsp?q=1&state=doQuery&showType=2&caseType=1&caseNo=%s&caseNo2=&isReadBulletinen_US=&isReadBulletinzh_TW=true&l6=zh_TW' %(case_no)\n",
    "                    res_img = requests.get(url_img, headers=headers)\n",
    "                    raw_img = json.loads(res_img.text)['datas']['SCN2']['fullFileName']\n",
    "                    url_images = 'https://twtmsearch.tipo.gov.tw/imageLoad.jsp?path=%s&formatName=jpeg&pathCodeId=282_pic'%(raw_img)\n",
    "\n",
    "                    # save image.\n",
    "                    if not os.path.exists('%s/%s/%s.jpg' %(paths[num],years[year],title_fore)):\n",
    "                        urllib.request.urlretrieve(url_images,'%s/%s/%s.jpg' %(paths[num],years[year],title_fore))\n",
    "                    \n",
    "                    #key:value\n",
    "                    values = [title_fore,kind_fore,mark_fore,url_images,content_fore]\n",
    "                    for n in range(len(keys)):\n",
    "                        d1[keys[n]]=values[n]\n",
    "                    \n",
    "                    #save jsonfile\n",
    "                    try:\n",
    "                        with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                            json.dump(d1, f, ensure_ascii=False)\n",
    "                            f.write('\\n')\n",
    "                    except FileNotFoundError as e:\n",
    "                        no_fore = no_fore.replace('/', '-')\n",
    "                        with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                            json.dump(d1, f, ensure_ascii=False)\n",
    "                            f.write('\\n')\n",
    "                    except OSError:\n",
    "                        pass\n",
    "                    print(\"save json complete!===========================================================\")\n",
    "\n",
    "                    #print result\n",
    "                    item_fore +=1\n",
    "                    if dkind[num] == \"OPP\":\n",
    "                        print(dkind[num],years[year],'fore: ',item_fore,\"/%s\"%(ZONE1_targets_fore[year]), title_fore)\n",
    "                    if dkind[num] == \"VAL\":\n",
    "                        print(dkind[num],years[year],'fore: ',item_fore,\"/%s\"%(ZONE2_targets_fore[year]), title_fore)\n",
    "                    if dkind[num] == \"REV\":\n",
    "                        print(dkind[num],years[year],'fore: ',item_fore,\"/%s\"%(ZONE3_targets_fore[year]), title_fore)\n",
    "                    \n",
    "                    #sleep\n",
    "                    sleep(randint(5,7))\n",
    "                    \n",
    "                except TypeError as e:\n",
    "                    print('==========')\n",
    "                    print(title_fore,': no content found')\n",
    "                    print(e.args)\n",
    "                    print('==========')\n",
    "                    continue\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print('==========')\n",
    "                    print(title_fore, ':no page found')\n",
    "                    print(e.args)\n",
    "                    print('==========')\n",
    "                    continue\n",
    "                    \n",
    "            #sleep range\n",
    "            sleep(randint(10,15))\n",
    "\n",
    "            # crawler back year data\n",
    "            for j in list_back['receiveData']['resultArr']:\n",
    "                d2 = {}\n",
    "                try:\n",
    "                    kind_back = j['DPT_KIND']\n",
    "                    mark_back = j['MARK_NAME']\n",
    "                    file_back = j['FILENAME']\n",
    "                    no_back = j['PUB_NO']\n",
    "                    title_back = no_back[-12:-1]\n",
    "                    data_sback = {'state': 'getContentByFileName',\n",
    "                                'filename': file_back\n",
    "                                 }\n",
    "                    res_sec_back = requests.post(url_each, headers=headers, data=data_sback)\n",
    "\n",
    "                    raw_content_back = json.loads(res_sec_back.text)\n",
    "                    content_back = raw_content_back['content']['content']\n",
    "\n",
    "\n",
    "                    #crawler image\n",
    "                    case_no2 = raw_content_back['content']['main'][77:118]\n",
    "                    url_img2 = 'https://twtmsearch.tipo.gov.tw/SS0/SS0201_q.jsp?q=1&state=doQuery&showType=2&caseType=1&caseNo=%s&caseNo2=&isReadBulletinen_US=&isReadBulletinzh_TW=true&l6=zh_TW' %(case_no2)\n",
    "                    res_img2 = requests.get(url_img2, headers=headers)\n",
    "                    raw_img2 = json.loads(res_img2.text)['datas']['SCN2']['fullFileName']\n",
    "                    url_images2 = 'https://twtmsearch.tipo.gov.tw/imageLoad.jsp?path=%s&formatName=jpeg&pathCodeId=282_pic'%(raw_img2)\n",
    "\n",
    "                    #save image\n",
    "                    if not os.path.exists('%s/%s/%s.jpg' %(paths[num],years[year],title_back)):\n",
    "                        urllib.request.urlretrieve(url_images2,'%s/%s/%s.jpg' %(paths[num],years[year],title_back))\n",
    "\n",
    "                    #key:value\n",
    "                    values = [title_back,kind_back,mark_back,url_images2,content_back]\n",
    "                    for n in range(len(keys)):\n",
    "                        d2[keys[n]]=values[n]\n",
    "                    \n",
    "                    #save jsonfile\n",
    "                    try:\n",
    "                        with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                            json.dump(d2, f, ensure_ascii=False)\n",
    "                            f.write('\\n')\n",
    "                    except FileNotFoundError as e:\n",
    "                        no_back = no_back.replace('/', '-')\n",
    "                        with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                            json.dump(d2, f, ensure_ascii=False)\n",
    "                            f.write('\\n')\n",
    "                    except OSError:\n",
    "                        pass\n",
    "                    print(\"save json complete!===========================================================\")\n",
    "            \n",
    "                    #print result\n",
    "                    item_back +=1\n",
    "                    if dkind[num] == \"OPP\":\n",
    "                        print(dkind[num],years[year],'back: ',item_back,\"/%s\"%(ZONE1_targets_back[year]), title_back)\n",
    "                    if dkind[num] == \"VAL\":\n",
    "                        print(dkind[num],years[year],'back: ',item_back,\"/%s\"%(ZONE2_targets_back[year]), title_back)\n",
    "                    if dkind[num] == \"REV\":\n",
    "                        print(dkind[num],years[year],'back: ',item_back,\"/%s\"%(ZONE3_targets_back[year]), title_back)\n",
    "                    \n",
    "                    #sleep\n",
    "                    sleep(randint(5,7))\n",
    "                    \n",
    "                except TypeError as e:\n",
    "                    print('==========')\n",
    "                    print(title_back,': no content found')\n",
    "                    print(e.args)\n",
    "                    print('==========')\n",
    "                    continue\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print('==========')\n",
    "                    print(title_back, ':no page found')\n",
    "                    print(e.args)\n",
    "                    print('==========')\n",
    "                    continue\n",
    "            \n",
    "            #sleep range\n",
    "            sleep(randint(10,15))\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print('==========')\n",
    "    #         print(res_fore.text)\n",
    "            print(e.args)\n",
    "            print('==========')\n",
    "            continue\n",
    "# sleep range (from 1 to 7)\n",
    "# print(item)\n",
    "# sleep(randint(1,7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
