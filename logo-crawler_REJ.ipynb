{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'queryResultJSONObject', 'searchConditions': '{\"datePubStart\":\"102/1/1\",\"datePubEnd\":\"102/1/10\",\"dptKind\":\"REJ\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-24ba283193c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                                 \u001b[1;31m#sleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                                 \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## download by REJ\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import urllib.request\n",
    "\n",
    "ZONE4_path = r'./ZONE4/'\n",
    "if not os.path.exists(ZONE4_path):\n",
    "    os.mkdir(ZONE4_path)\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'}\n",
    "\n",
    "url_start = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp?tid=5f1da434-ad44-4955-97d3-1ac4433603f1(203.204.81.115)'\n",
    "# url_start = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp?tid=f61d5b9e-0eb7-4160-86c9-ab76e064cb8c(111.249.61.96)'\n",
    "url_each = 'https://twtmsearch.tipo.gov.tw/OS0/OS0401_q.jsp'\n",
    "\n",
    "dkind = [\"REJ\"]  # \"REJ\" over 130K\n",
    "paths = [ZONE4_path]\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "years = [102, 103, 104, 105, 106, 107, 108, 109]\n",
    "m31 = [1, 3, 5, 7, 8, 10, 12]\n",
    "m30 = [4, 6, 9, 11]\n",
    "m29 = [2]\n",
    "days_sta = [1,11,21,26]\n",
    "\n",
    "# ZONE4_targets = [399,349,384,359,307,386,384,273]\n",
    "# ZONE4_targets_back = [496,410,374,381,342,429,358,192]\n",
    "\n",
    "keys = [\"title\", \"kind\", \"markname\", \"content\"]\n",
    "\n",
    "for num in range(1):\n",
    "    # select type of judgement.\n",
    "#     print(\"now is : kind\", dkind[num])\n",
    "\n",
    "    # year period select\n",
    "    for year in range(8):\n",
    "        try:\n",
    "            for month in range(12):\n",
    "#                 print(\"now\",month,\"mon\", months[month])\n",
    "                if months[month] in m31:\n",
    "                    lastday = 31\n",
    "                    days_end = [10, 20, 25, 31]\n",
    "                    for dayend,daysta in zip(range(4),range(4)):\n",
    "                        data_REJ = {'state': 'queryResultJSONObject',\n",
    "                                         'searchConditions': '{\"datePubStart\":\"%s/%s/%s\",\"datePubEnd\":\"%s/%s/%s\",\"dptKind\":\"%s\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'\n",
    "                                        %(years[year], months[month],days_sta[daysta],years[year], months[month],days_end[dayend],dkind[num])\n",
    "                                         }\n",
    "                        res_REJ = requests.post(url_start, headers=headers, data=data_REJ)\n",
    "                        list_REJ = json.loads(res_REJ.text)\n",
    "                        item_REJ = 0\n",
    "                       \n",
    "                        for i in list_REJ['receiveData']['resultArr']:\n",
    "                            d1 = {}\n",
    "                            try:\n",
    "                                kind_REJ = i['DPT_KIND']\n",
    "                                mark_REJ = i['MARK_NAME']\n",
    "                                no_REJ = i['PUB_NO']\n",
    "                                title_REJ = no_REJ[-12:-1]\n",
    "                                file_REJ = i['FILENAME']\n",
    "                                data_REJ  = {'state': 'getContentByFileName',\n",
    "                                            'filename': file_REJ\n",
    "                                             }\n",
    "    \n",
    "                                # crawler content\n",
    "                                res_sec_REJ = requests.post(url_each, headers=headers, data=data_REJ)\n",
    "                                raw_content_REJ = json.loads(res_sec_REJ.text)\n",
    "                                content_REJ = raw_content_REJ['content']['content']\n",
    "    \n",
    "                                #key:value\n",
    "                                values = [title_REJ,kind_REJ,mark_REJ,content_REJ]\n",
    "                                for n in range(len(keys)):\n",
    "                                    d1[keys[n]]=values[n]\n",
    "    \n",
    "                                #save jsonfile\n",
    "                                try:\n",
    "                                    with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except FileNotFoundError as e:\n",
    "                                    no_REJ = no_REJ.replace('/', '-')\n",
    "                                    with open('%s/%s.json' %(paths[num],years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except OSError:\n",
    "                                    pass\n",
    "#                                 print(\"save json complete!===========================================================\")\n",
    "    \n",
    "                                #print result\n",
    "#                                 item_REJ += 1\n",
    "#                                 if dkind[num] == \"REJ\":\n",
    "#                                     print(dkind[num],years[year],'REJ: ',item_REJ, title_REJ)\n",
    "                                    \n",
    "                                #sleep\n",
    "                                sleep(randint(5,7))\n",
    "    \n",
    "                            except TypeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ,': no content found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ, ':no page found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "    \n",
    "                        #sleep range\n",
    "                        sleep(randint(10,15))\n",
    "\n",
    "                #date_30\n",
    "                elif months[month] in m30:\n",
    "                    lastday = 30\n",
    "                    days_end = [10, 20, 25, 30]\n",
    "                    for dayend,daysta in zip(range(4),range(4)):\n",
    "                        data_REJ = {'state': 'queryResultJSONObject',\n",
    "                                         'searchConditions': '{\"datePubStart\":\"%s/%s/%s\",\"datePubEnd\":\"%s/%s/%s\",\"dptKind\":\"%s\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'\n",
    "                                        % (years[year], months[month], days_sta[daysta], years[year],months[month], days_end[dayend], dkind[num])\n",
    "                                         }\n",
    "                        res_REJ = requests.post(url_start, headers=headers, data=data_REJ)\n",
    "                        list_REJ = json.loads(res_REJ.text)\n",
    "                        #                     pp.pprint(list_REJ)\n",
    "#                         print('totalnum', years[year], \"month:\",months[month],\"section:\",daysta,list_REJ['receiveData']['totalNum'])\n",
    "                        item_REJ = 0\n",
    "                        \n",
    "                        for i in list_REJ['receiveData']['resultArr']:\n",
    "                            d1 = {}\n",
    "                            try:\n",
    "                                kind_REJ = i['DPT_KIND']\n",
    "                                mark_REJ = i['MARK_NAME']\n",
    "                                no_REJ = i['PUB_NO']\n",
    "                                title_REJ = no_REJ[-12:-1]\n",
    "                                file_REJ = i['FILENAME']\n",
    "                                data_REJ = {'state': 'getContentByFileName',\n",
    "                                            'filename': file_REJ\n",
    "                                            }\n",
    "\n",
    "                                # crawler content\n",
    "                                res_sec_REJ = requests.post(url_each, headers=headers, data=data_REJ)\n",
    "                                raw_content_REJ = json.loads(res_sec_REJ.text)\n",
    "                                content_REJ = raw_content_REJ['content']['content']\n",
    "\n",
    "                                # key:value\n",
    "                                values = [title_REJ, kind_REJ, mark_REJ, content_REJ]\n",
    "                                for n in range(len(keys)):\n",
    "                                    d1[keys[n]] = values[n]\n",
    "\n",
    "                                # save jsonfile\n",
    "                                try:\n",
    "                                    with open('%s/%s.json' % (paths[num], years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except FileNotFoundError as e:\n",
    "                                    no_REJ = no_REJ.replace('/', '-')\n",
    "                                    with open('%s/%s.json' % (paths[num], years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except OSError:\n",
    "                                    pass\n",
    "#                                 print(\"save json complete!===========================================================\")\n",
    "\n",
    "#                                 # print result\n",
    "#                                 item_REJ += 1\n",
    "#                                 if dkind[num] == \"REJ\":\n",
    "#                                     print(dkind[num], years[year], 'REJ: ', item_REJ, title_REJ)\n",
    "\n",
    "                                # sleep\n",
    "                                sleep(randint(5, 7))\n",
    "\n",
    "                            except TypeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ, ': no content found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ, ':no page found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "\n",
    "                # date_29\n",
    "                else: #months[month] in m29\n",
    "                    lastday = 29\n",
    "                    days_end = [10, 20, 25,29]\n",
    "                    for dayend,daysta in zip(range(4),range(4)):\n",
    "                        data_REJ = {'state': 'queryResultJSONObject',\n",
    "                                         'searchConditions': '{\"datePubStart\":\"%s/%s/%s\",\"datePubEnd\":\"%s/%s/%s\",\"dptKind\":\"%s\",\"userType\":\"=====請選擇=====\",\"boolean1\":\"=====請選擇=====\",\"boolean2\":\"=====請選擇=====\"}'\n",
    "                                         %(years[year], months[month], days_sta[daysta], years[year],months[month], days_end[dayend], dkind[num])\n",
    "                                         }\n",
    "                        res_REJ = requests.post(url_start, headers=headers, data=data_REJ)\n",
    "                        list_REJ = json.loads(res_REJ.text)\n",
    "                        #                     pp.pprint(list_REJ)\n",
    "#                         print('totalnum', years[year], \"month:\",months[month],\"section:\",daysta,list_REJ['receiveData']['totalNum'])\n",
    "                        item_REJ = 0\n",
    "                        \n",
    "                        for i in list_REJ['receiveData']['resultArr']:\n",
    "                            d1 = {}\n",
    "                            try:\n",
    "                                kind_REJ = i['DPT_KIND']\n",
    "                                mark_REJ = i['MARK_NAME']\n",
    "                                no_REJ = i['PUB_NO']\n",
    "                                title_REJ = no_REJ[-12:-1]\n",
    "                                file_REJ = i['FILENAME']\n",
    "                                data_REJ = {'state': 'getContentByFileName',\n",
    "                                            'filename': file_REJ\n",
    "                                            }\n",
    "\n",
    "                                # crawler content\n",
    "                                res_sec_REJ = requests.post(url_each, headers=headers, data=data_REJ)\n",
    "                                raw_content_REJ = json.loads(res_sec_REJ.text)\n",
    "                                content_REJ = raw_content_REJ['content']['content']\n",
    "\n",
    "                                # key:value\n",
    "                                values = [title_REJ, kind_REJ, mark_REJ, content_REJ]\n",
    "                                for n in range(len(keys)):\n",
    "                                    d1[keys[n]] = values[n]\n",
    "\n",
    "                                # save jsonfile\n",
    "                                try:\n",
    "                                    with open('%s/%s.json' % (paths[num], years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except FileNotFoundError as e:\n",
    "                                    no_REJ = no_REJ.replace('/', '-')\n",
    "                                    with open('%s/%s.json' % (paths[num], years[year]), 'a', encoding='utf-8') as f:\n",
    "                                        json.dump(d1, f, ensure_ascii=False)\n",
    "                                        f.write('\\n')\n",
    "                                except OSError:\n",
    "                                    pass\n",
    "#                                 print(\"save json complete!===========================================================\")\n",
    "\n",
    "                                # print result\n",
    "#                                 item_REJ += 1\n",
    "#                                 if dkind[num] == \"REJ\":\n",
    "#                                     print(dkind[num], years[year], 'REJ: ', item_REJ, title_REJ)\n",
    "\n",
    "                                # sleep\n",
    "                                sleep(randint(5, 7))\n",
    "\n",
    "                            except TypeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ, ': no content found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print('==========')\n",
    "                                print(title_REJ, ':no page found')\n",
    "                                print(e.args)\n",
    "                                print('==========')\n",
    "                                continue\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print('==========')\n",
    "            #         print(res_REJ.text)\n",
    "            print(e.args)\n",
    "            print('==========')\n",
    "            continue\n",
    "# sleep range (from 1 to 7)\n",
    "# print(item)\n",
    "# sleep(randint(1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
